2024-06-22 00:06:04.292929: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 00:06:04.298582: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 00:06:04.380956: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 00:06:05.736121: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-22 00:06:08,622 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 00:06:08,622 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 00:06:08,625 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
2024-06-22 00:06:16,742 - INFO - Data type of batch before model apply: <dtype: 'int32'>
Type of logits: <class 'function'>
jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 150, in <module>
    train_model(data_file)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 1188, in wrapper
    val = prof(func)(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 761, in f
    return func(*args, **kwds)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 136, in train_model
    loss, params, opt_state = train_step(params, transformed_forward, optimizer, batch, labels, step_rng)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 79, in train_step
    loss, grads = jax.value_and_grad(jax.checkpoint(loss_fn))(params)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 71, in loss_fn
    assert hasattr(logits, 'shape'), f"Logits should be a tensor, but got {type(logits)}"
AssertionError: Logits should be a tensor, but got <class 'function'>
2024-06-22 00:11:38.774618: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 00:11:38.780285: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 00:11:38.865641: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 00:11:40.251721: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-22 00:11:43,086 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 00:11:43,087 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 00:11:43,090 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
2024-06-22 00:11:51,107 - INFO - Data type of batch before model apply: <dtype: 'int32'>
Type of logits: <class 'function'>
jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 150, in <module>
    train_model(data_file)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 1188, in wrapper
    val = prof(func)(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 761, in f
    return func(*args, **kwds)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 136, in train_model
    loss, params, opt_state = train_step(params, transformed_forward, optimizer, batch, labels, step_rng)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 79, in train_step
    loss, grads = jax.value_and_grad(jax.checkpoint(loss_fn))(params)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 71, in loss_fn
    assert hasattr(logits, 'shape'), f"Logits should be a tensor, but got {type(logits)}"
AssertionError: Logits should be a tensor, but got <class 'function'>
2024-06-22 00:20:53.709591: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 00:20:53.715414: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 00:20:53.803193: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 00:20:55.113414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-22 00:20:58,023 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 00:20:58,024 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 00:20:58,026 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 151, in <module>
    train_model(data_file)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 1188, in wrapper
    val = prof(func)(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 761, in f
    return func(*args, **kwds)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 126, in train_model
    params = transformed_forward.init(init_rng, example_batch)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 166, in init_fn
    params, state = f.init(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 422, in init_fn
    f(*args, **kwargs)
TypeError: train_model.<locals>.forward_fn() missing 2 required positional arguments: 'rng' and 'batch'
2024-06-22 00:43:40.136101: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 00:43:40.141790: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 00:43:40.227590: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 00:43:41.519843: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-22 00:43:44,491 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 00:43:44,491 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 00:43:44,495 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 151, in <module>
    train_model(data_file)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 1188, in wrapper
    val = prof(func)(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 761, in f
    return func(*args, **kwds)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 126, in train_model
    params = transformed_forward.init(init_rng, example_batch)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 166, in init_fn
    params, state = f.init(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 422, in init_fn
    f(*args, **kwargs)
TypeError: train_model.<locals>.forward_fn() missing 2 required positional arguments: 'params' and 'rng'
2024-06-22 01:28:02.750727: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 01:28:02.756729: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 01:28:02.841137: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 01:28:04.135885: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-22 01:28:07,070 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 01:28:07,070 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 01:28:07,075 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 151, in <module>
    train_model(data_file)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 1188, in wrapper
    val = prof(func)(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 761, in f
    return func(*args, **kwds)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 126, in train_model
    params = transformed_forward.init(init_rng, example_batch)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 166, in init_fn
    params, state = f.init(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 422, in init_fn
    f(*args, **kwargs)
TypeError: train_model.<locals>.forward_fn() missing 1 required positional argument: 'rng'
2024-06-22 02:02:33.197431: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 02:02:33.203175: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 02:02:33.290435: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 02:02:34.552059: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-22 02:02:37,431 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 02:02:37,432 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 02:02:37,435 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
Data type of inputs after conversion: <dtype: 'int32'>
Data type of inputs before embedding layer: <dtype: 'int32'>
Data type of inputs after conversion to int32: <dtype: 'int32'>
Data type of inputs before transformer apply: <dtype: 'int32'>
Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 151, in <module>
    train_model(data_file)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 1188, in wrapper
    val = prof(func)(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 761, in f
    return func(*args, **kwds)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 126, in train_model
    params = transformed_forward.init(init_rng, example_batch, rng)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 166, in init_fn
    params, state = f.init(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 422, in init_fn
    f(*args, **kwargs)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 101, in forward_fn
    logits = model(batch, rng)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 464, in wrapped
    out = f(*args, **kwargs)
  File "/usr/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 305, in run_interceptors
    return bound_method(*args, **kwargs)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/model_architecture.py", line 72, in __call__
    embedded_inputs = self.transformer.apply(rng, inputs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 183, in apply_fn
    out, state = f.apply(params, None, *args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 449, in apply_fn
    params = check_mapping("params", params)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 505, in check_mapping
    raise TypeError(f"{name} argument does not appear valid. It should be a "
TypeError: params argument does not appear valid. It should be a mapping but is of type <class 'jaxlib.xla_extension.ArrayImpl'>. For reference the parameters for apply are `apply(params, rng, ...)`` for `hk.transform` and `apply(params, state, rng, ...)` for `hk.transform_with_state`.
The argument was: Array([2465931498, 3679230171], dtype=uint32).
mprof: Sampling memory every 0.1s
running new process
2024-06-22 02:10:05.724143: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 02:10:05.729872: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 02:10:05.816714: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 02:10:07.216239: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-22 02:10:10,199 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 02:10:10,200 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 02:10:10,202 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 151, in <module>
    train_model(data_file)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 1188, in wrapper
    val = prof(func)(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 761, in f
    return func(*args, **kwds)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 126, in train_model
    params = transformed_forward.init(init_rng, example_batch, rng)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 166, in init_fn
    params, state = f.init(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 422, in init_fn
    f(*args, **kwargs)
TypeError: train_model.<locals>.forward_fn() takes 1 positional argument but 2 were given
2024-06-22 02:22:08.627069: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 02:22:08.632879: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 02:22:08.719977: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 02:22:10.029889: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-22 02:22:13,054 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 02:22:13,055 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 02:22:13,058 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
Data type of inputs after conversion: <dtype: 'int32'>
Data type of inputs before embedding layer: <dtype: 'int32'>
Data type of inputs after conversion to int32: <dtype: 'int32'>
Data type of inputs before transformer apply: <dtype: 'int32'>
Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 151, in <module>
    train_model(data_file)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 1188, in wrapper
    val = prof(func)(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 761, in f
    return func(*args, **kwds)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 126, in train_model
    params = transformed_forward.init(init_rng, example_batch, rng)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 422, in init_fn
    f(*args, **kwargs)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 101, in forward_fn
    logits = model(batch, rng)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 464, in wrapped
    out = f(*args, **kwargs)
  File "/usr/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 305, in run_interceptors
    return bound_method(*args, **kwargs)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/model_architecture.py", line 72, in __call__
    embedded_inputs = self.transformer.apply(inputs, rng)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 183, in apply_fn
    out, state = f.apply(params, None, *args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 449, in apply_fn
    params = check_mapping("params", params)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 505, in check_mapping
    raise TypeError(f"{name} argument does not appear valid. It should be a "
TypeError: params argument does not appear valid. It should be a mapping but is of type <class 'tensorflow.python.framework.ops.EagerTensor'>. For reference the parameters for apply are `apply(params, rng, ...)`` for `hk.transform` and `apply(params, state, rng, ...)` for `hk.transform_with_state`.
The argument was: <tf.Tensor: shape=(8, 32), dtype=int32, numpy=
array([[  166,  2019,     3, 15198,     3,  1927,  1496,  1396,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0],
       [  166,  2019,     3,    26,   354,  1396,     3,    23,    26,
          226,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0],
       [    3,  5472,     9,   115,    16,    17,    40,   508,   349,
         5538,     3,    15,    17,    89,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0],
       [    3,  5472,     9,   115,  4519,     3,    17,    52,  4431,
           16,    17,    40,   508,   576,  5538,     3,    15,    17,
           89,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0],
       [ 4049, 11010,   422,  2468,  5538,     3,     9,    26,    51,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0],
       [ 4049, 11010,   422,    18,  4010,  5538,  3069,    16,     7,
           17,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0],
       [  146,  1050,   827, 11736,   126,     3,   287,   126,    19,
           77,  1713,   302,   591,     3,  3843,    32,    40,  1713,
          115,   940,   354,   172,     7,   157,   632,     0,     0,
            0,     0,     0,     0,     0],
       [  146,  1050,   827, 11736,   126,     3,   287,   126,    19,
           77,  1713,   302, 26755,  4853,    75,  1755,  3628,     3,
         3843,    32,    40,  1713,   115,   940,   354,   172,     7,
            0,     0,     0,     0,     0]], dtype=int32)>.
2024-06-22 03:02:32.623115: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 03:02:32.628971: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 03:02:32.716024: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 03:02:33.986831: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-22 03:02:36,462 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 03:02:36,462 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 03:02:36,463 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 151, in <module>
    train_model(data_file)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 126, in train_model
    params = transformed_forward.init(init_rng, example_batch)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 166, in init_fn
    params, state = f.init(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 422, in init_fn
    f(*args, **kwargs)
TypeError: train_model.<locals>.forward_fn() missing 1 required positional argument: 'rng'
2024-06-22 03:11:30.900615: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 03:11:30.906426: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 03:11:30.995321: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 03:11:32.405680: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-22 03:11:35,010 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 03:11:35,010 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 03:11:35,011 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 151, in <module>
    train_model(data_file)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 126, in train_model
    params = transformed_forward.init(init_rng, example_batch)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 166, in init_fn
    params, state = f.init(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 422, in init_fn
    f(*args, **kwargs)
TypeError: train_model.<locals>.forward_fn() missing 1 required positional argument: 'rng'
2024-06-22 03:28:08.675595: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 03:28:08.681433: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 03:28:08.771497: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 03:28:10.097964: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-22 03:28:12,641 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 03:28:12,641 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 03:28:12,642 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 151, in <module>
    train_model(data_file)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 126, in train_model
    params = transformed_forward.init(init_rng, example_batch)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 166, in init_fn
    params, state = f.init(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 422, in init_fn
    f(*args, **kwargs)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 101, in forward_fn
    logits = model(batch)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 464, in wrapped
    out = f(*args, **kwargs)
  File "/usr/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 305, in run_interceptors
    return bound_method(*args, **kwargs)
TypeError: VishwamAIModel.__call__() missing 1 required positional argument: 'rng'
2024-06-22 03:39:13.789292: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 03:39:13.795208: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 03:39:13.881715: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 03:39:15.145139: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-22 03:39:17,502 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 03:39:17,502 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 03:39:17,503 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
Data type of inputs after conversion: <dtype: 'int32'>
Data type of inputs before embedding layer: <dtype: 'int32'>
Data type of inputs after conversion to int32: <dtype: 'int32'>
Data type of inputs before transformer apply: <dtype: 'int32'>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 126, in to_prng_sequence
    rng = hk.PRNGSequence(rng)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/base.py", line 1046, in __init__
    assert_is_prng_key(key_or_seed)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/base.py", line 980, in assert_is_prng_key
    is_typed_prng = jax.dtypes.issubdtype(key.dtype, jax.dtypes.prng_key)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/jax/_src/dtypes.py", line 347, in issubdtype
    a if isinstance(a, (type, np.dtype, ExtendedDType)) else np.dtype(a),  # type: ignore[arg-type]
TypeError: Cannot interpret 'tf.int32' as a data type

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 150, in <module>
    train_model(data_file)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 125, in train_model
    params = transformed_forward.init(init_rng, example_batch)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 166, in init_fn
    params, state = f.init(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 422, in init_fn
    f(*args, **kwargs)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 100, in forward_fn
    logits = model(batch)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 464, in wrapped
    out = f(*args, **kwargs)
  File "/usr/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 305, in run_interceptors
    return bound_method(*args, **kwargs)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/model_architecture.py", line 72, in __call__
    embedded_inputs = self.transformer.apply(None, inputs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 183, in apply_fn
    out, state = f.apply(params, None, *args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 451, in apply_fn
    rng = to_prng_sequence(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 128, in to_prng_sequence
    raise ValueError(
ValueError: Apply must be called with an RNG as the second argument, the required signature is: `apply(params, rng, *a, **k)`. The object was of type <class 'tensorflow.python.framework.ops.EagerTensor'>: [[  166  2019     3 15198     3  1927  1496  1396     0     0     0     0
      0     0     0     0     0     0     0     0     0     0     0     0
      0     0     0     0     0     0     0     0]
 [  166  2019     3    26   354  1396     3    23    26   226     0     0
      0     0     0     0     0     0     0     0     0     0     0     0
      0     0     0     0     0     0     0     0]
 [    3  5472     9   115    16    17    40   508   349  5538     3    15
     17    89     0     0     0     0     0     0     0     0     0     0
      0     0     0     0     0     0     0     0]
 [    3  5472     9   115  4519     3    17    52  4431    16    17    40
    508   576  5538     3    15    17    89     0     0     0     0     0
      0     0     0     0     0     0     0     0]
 [ 4049 11010   422  2468  5538     3     9    26    51     0     0     0
      0     0     0     0     0     0     0     0     0     0     0     0
      0     0     0     0     0     0     0     0]
 [ 4049 11010   422    18  4010  5538  3069    16     7    17     0     0
      0     0     0     0     0     0     0     0     0     0     0     0
      0     0     0     0     0     0     0     0]
 [  146  1050   827 11736   126     3   287   126    19    77  1713   302
    591     3  3843    32    40  1713   115   940   354   172     7   157
    632     0     0     0     0     0     0     0]
 [  146  1050   827 11736   126     3   287   126    19    77  1713   302
  26755  4853    75  1755  3628     3  3843    32    40  1713   115   940
    354   172     7     0     0     0     0     0]]
2024-06-22 03:46:22.439649: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 03:46:22.445383: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 03:46:22.531421: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 03:46:23.823998: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-22 03:46:26,180 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 03:46:26,181 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 03:46:26,182 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
Data type of inputs after conversion: <dtype: 'int32'>
Data type of inputs before embedding layer: <dtype: 'int32'>
Data type of inputs after conversion to int32: <dtype: 'int32'>
Data type of inputs before transformer apply: <dtype: 'int32'>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 126, in to_prng_sequence
    rng = hk.PRNGSequence(rng)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/base.py", line 1046, in __init__
    assert_is_prng_key(key_or_seed)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/base.py", line 980, in assert_is_prng_key
    is_typed_prng = jax.dtypes.issubdtype(key.dtype, jax.dtypes.prng_key)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/jax/_src/dtypes.py", line 347, in issubdtype
    a if isinstance(a, (type, np.dtype, ExtendedDType)) else np.dtype(a),  # type: ignore[arg-type]
TypeError: Cannot interpret 'tf.int32' as a data type

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 150, in <module>
    train_model(data_file)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 125, in train_model
    params = transformed_forward.init(init_rng, example_batch)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 166, in init_fn
    params, state = f.init(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 422, in init_fn
    f(*args, **kwargs)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 100, in forward_fn
    logits = model(batch)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 464, in wrapped
    out = f(*args, **kwargs)
  File "/usr/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 305, in run_interceptors
    return bound_method(*args, **kwargs)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/model_architecture.py", line 72, in __call__
    embedded_inputs = self.transformer.apply(None, inputs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 183, in apply_fn
    out, state = f.apply(params, None, *args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 451, in apply_fn
    rng = to_prng_sequence(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 128, in to_prng_sequence
    raise ValueError(
ValueError: Apply must be called with an RNG as the second argument, the required signature is: `apply(params, rng, *a, **k)`. The object was of type <class 'tensorflow.python.framework.ops.EagerTensor'>: [[  166  2019     3 15198     3  1927  1496  1396     0     0     0     0
      0     0     0     0     0     0     0     0     0     0     0     0
      0     0     0     0     0     0     0     0]
 [  166  2019     3    26   354  1396     3    23    26   226     0     0
      0     0     0     0     0     0     0     0     0     0     0     0
      0     0     0     0     0     0     0     0]
 [    3  5472     9   115    16    17    40   508   349  5538     3    15
     17    89     0     0     0     0     0     0     0     0     0     0
      0     0     0     0     0     0     0     0]
 [    3  5472     9   115  4519     3    17    52  4431    16    17    40
    508   576  5538     3    15    17    89     0     0     0     0     0
      0     0     0     0     0     0     0     0]
 [ 4049 11010   422  2468  5538     3     9    26    51     0     0     0
      0     0     0     0     0     0     0     0     0     0     0     0
      0     0     0     0     0     0     0     0]
 [ 4049 11010   422    18  4010  5538  3069    16     7    17     0     0
      0     0     0     0     0     0     0     0     0     0     0     0
      0     0     0     0     0     0     0     0]
 [  146  1050   827 11736   126     3   287   126    19    77  1713   302
    591     3  3843    32    40  1713   115   940   354   172     7   157
    632     0     0     0     0     0     0     0]
 [  146  1050   827 11736   126     3   287   126    19    77  1713   302
  26755  4853    75  1755  3628     3  3843    32    40  1713   115   940
    354   172     7     0     0     0     0     0]]
2024-06-22 04:54:14.791892: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 04:54:14.797954: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 04:54:14.881962: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 04:54:16.260701: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-22 04:54:18,606 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 04:54:18,606 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 04:54:18,607 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 151, in <module>
    train_model(data_file)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 126, in train_model
    params = transformed_forward.init(init_rng, example_batch, init_rng)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 166, in init_fn
    params, state = f.init(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 422, in init_fn
    f(*args, **kwargs)
TypeError: train_model.<locals>.forward_fn() missing 1 required positional argument: 'rng'
2024-06-22 05:02:15.115316: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 05:02:15.121022: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 05:02:15.209878: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 05:02:16.474587: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-22 05:02:18,840 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 05:02:18,840 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 05:02:18,842 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 151, in <module>
    train_model(data_file)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 126, in train_model
    params = transformed_forward.init(init_rng, example_batch)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 166, in init_fn
    params, state = f.init(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 422, in init_fn
    f(*args, **kwargs)
TypeError: train_model.<locals>.forward_fn() missing 2 required positional arguments: 'batch' and 'rng'
