model:
  type: Vishwamai
  size: 7b
  layers: 32
  hidden_size: 4096
  attention_heads: 32
  dropout: 0.1

training:
  batch_size: 16
  learning_rate: 3e-5
  epochs: 10
  optimizer: AdamW
  scheduler: linear

data:
  train_dataset: path/to/train_dataset
  validation_dataset: path/to/validation_dataset

evaluation:
  metrics:
    - name: Perplexity
    - name: BLEU
    - name: ROUGE
