2024-06-22 08:53:36.134160: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 08:53:36.142188: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 08:53:36.239961: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 08:53:37.697097: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-22 08:53:40,467 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 08:53:40,467 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 08:53:40,469 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
Data type of inputs after conversion: <dtype: 'int32'>
Data type of inputs before embedding layer: <dtype: 'int32'>
Data type of inputs after conversion to int32: <dtype: 'int32'>
Data type of embedded inputs after embedding layer: float32
Data type of inputs before transformer apply: float32
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 126, in to_prng_sequence
    rng = hk.PRNGSequence(rng)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/base.py", line 1046, in __init__
    assert_is_prng_key(key_or_seed)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/base.py", line 1004, in assert_is_prng_key
    raise ValueError(
ValueError: Provided key did not have expected shape and/or dtype: expected=(shape=(2,), dtype=uint32), actual=(shape=(8, 32, 64), dtype=float32)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 155, in <module>
    train_model(data_file)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 130, in train_model
    params = transformed_forward.init(init_rng, example_batch)  # Pass the correct arguments
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 166, in init_fn
    params, state = f.init(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 422, in init_fn
    f(*args, **kwargs)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 105, in forward_fn
    logits = model(batch)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 464, in wrapped
    out = f(*args, **kwargs)
  File "/usr/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 305, in run_interceptors
    return bound_method(*args, **kwargs)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/model_architecture.py", line 77, in __call__
    transformer_output = self.transformer.apply(None, embedded_inputs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 183, in apply_fn
    out, state = f.apply(params, None, *args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 451, in apply_fn
    rng = to_prng_sequence(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 128, in to_prng_sequence
    raise ValueError(
ValueError: Apply must be called with an RNG as the second argument, the required signature is: `apply(params, rng, *a, **k)`. The object was of type <class 'jaxlib.xla_extension.ArrayImpl'>: [[[-0.00957099 -0.0042609   0.00340895 ...  0.00261725 -0.00052745
   -0.00532985]
  [-0.00553907  0.00588879  0.01242392 ...  0.01528201 -0.00297135
    0.01714389]
  [ 0.01099068  0.00933441  0.00521326 ...  0.01280174 -0.00509705
    0.00325228]
  ...
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]]

 [[-0.00957099 -0.0042609   0.00340895 ...  0.00261725 -0.00052745
   -0.00532985]
  [-0.00553907  0.00588879  0.01242392 ...  0.01528201 -0.00297135
    0.01714389]
  [ 0.01099068  0.00933441  0.00521326 ...  0.01280174 -0.00509705
    0.00325228]
  ...
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]]

 [[ 0.01099068  0.00933441  0.00521326 ...  0.01280174 -0.00509705
    0.00325228]
  [ 0.0070703  -0.00351574 -0.00975035 ... -0.00747036  0.00742292
   -0.00616953]
  [-0.01405564 -0.00126728  0.01278545 ...  0.00584597  0.018904
    0.00264597]
  ...
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]]

 ...

 [[ 0.00240181  0.00471304  0.00595017 ...  0.00469747  0.0094203
   -0.00659482]
  [ 0.004988    0.01414642  0.01769772 ... -0.00013558  0.00023749
   -0.01101039]
  [ 0.02158225 -0.00600585  0.00033362 ...  0.00391613  0.01691691
   -0.00290484]
  ...
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]]

 [[ 0.0187214   0.00175198 -0.00095723 ...  0.0177877   0.00674335
   -0.00305236]
  [ 0.00195901 -0.00964023  0.00302406 ... -0.00480226 -0.01641154
    0.00061692]
  [ 0.00773156  0.01634322 -0.01234329 ...  0.00199128  0.00440729
    0.00442611]
  ...
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]]

 [[ 0.0187214   0.00175198 -0.00095723 ...  0.0177877   0.00674335
   -0.00305236]
  [ 0.00195901 -0.00964023  0.00302406 ... -0.00480226 -0.01641154
    0.00061692]
  [ 0.00773156  0.01634322 -0.01234329 ...  0.00199128  0.00440729
    0.00442611]
  ...
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]]]
2024-06-22 09:05:17.888026: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 09:05:17.894677: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 09:05:17.990534: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 09:05:19.415439: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-22 09:05:22,482 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 09:05:22,482 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 09:05:22,483 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
Data type of inputs after conversion: <dtype: 'int32'>
Data type of inputs before embedding layer: <dtype: 'int32'>
Data type of inputs after conversion to int32: <dtype: 'int32'>
Data type of embedded inputs after embedding layer: float32
Data type of inputs before transformer apply: float32
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 126, in to_prng_sequence
    rng = hk.PRNGSequence(rng)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/base.py", line 1046, in __init__
    assert_is_prng_key(key_or_seed)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/base.py", line 1004, in assert_is_prng_key
    raise ValueError(
ValueError: Provided key did not have expected shape and/or dtype: expected=(shape=(2,), dtype=uint32), actual=(shape=(8, 32, 64), dtype=float32)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 154, in <module>
    train_model(data_file)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 129, in train_model
    params = transformed_forward.init(init_rng, example_batch)  # Pass the correct arguments
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 166, in init_fn
    params, state = f.init(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 422, in init_fn
    f(*args, **kwargs)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 104, in forward_fn
    logits = model(batch)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 464, in wrapped
    out = f(*args, **kwargs)
  File "/usr/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 305, in run_interceptors
    return bound_method(*args, **kwargs)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/model_architecture.py", line 77, in __call__
    transformer_output = self.transformer.apply(None, embedded_inputs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 183, in apply_fn
    out, state = f.apply(params, None, *args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 451, in apply_fn
    rng = to_prng_sequence(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 128, in to_prng_sequence
    raise ValueError(
ValueError: Apply must be called with an RNG as the second argument, the required signature is: `apply(params, rng, *a, **k)`. The object was of type <class 'jaxlib.xla_extension.ArrayImpl'>: [[[-0.00957099 -0.0042609   0.00340895 ...  0.00261725 -0.00052745
   -0.00532985]
  [-0.00553907  0.00588879  0.01242392 ...  0.01528201 -0.00297135
    0.01714389]
  [ 0.01099068  0.00933441  0.00521326 ...  0.01280174 -0.00509705
    0.00325228]
  ...
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]]

 [[-0.00957099 -0.0042609   0.00340895 ...  0.00261725 -0.00052745
   -0.00532985]
  [-0.00553907  0.00588879  0.01242392 ...  0.01528201 -0.00297135
    0.01714389]
  [ 0.01099068  0.00933441  0.00521326 ...  0.01280174 -0.00509705
    0.00325228]
  ...
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]]

 [[ 0.01099068  0.00933441  0.00521326 ...  0.01280174 -0.00509705
    0.00325228]
  [ 0.0070703  -0.00351574 -0.00975035 ... -0.00747036  0.00742292
   -0.00616953]
  [-0.01405564 -0.00126728  0.01278545 ...  0.00584597  0.018904
    0.00264597]
  ...
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]]

 ...

 [[ 0.00240181  0.00471304  0.00595017 ...  0.00469747  0.0094203
   -0.00659482]
  [ 0.004988    0.01414642  0.01769772 ... -0.00013558  0.00023749
   -0.01101039]
  [ 0.02158225 -0.00600585  0.00033362 ...  0.00391613  0.01691691
   -0.00290484]
  ...
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]]

 [[ 0.0187214   0.00175198 -0.00095723 ...  0.0177877   0.00674335
   -0.00305236]
  [ 0.00195901 -0.00964023  0.00302406 ... -0.00480226 -0.01641154
    0.00061692]
  [ 0.00773156  0.01634322 -0.01234329 ...  0.00199128  0.00440729
    0.00442611]
  ...
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]]

 [[ 0.0187214   0.00175198 -0.00095723 ...  0.0177877   0.00674335
   -0.00305236]
  [ 0.00195901 -0.00964023  0.00302406 ... -0.00480226 -0.01641154
    0.00061692]
  [ 0.00773156  0.01634322 -0.01234329 ...  0.00199128  0.00440729
    0.00442611]
  ...
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]
  [-0.00297072  0.01160661  0.00799139 ...  0.00880169 -0.00936524
    0.00931786]]]
2024-06-22 09:38:22.729396: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 09:38:22.737109: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 09:38:22.831356: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 09:38:24.289236: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-22 09:38:27,059 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 09:38:27,059 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 09:38:27,060 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 154, in <module>
    train_model(data_file)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 129, in train_model
    params = transformed_forward.init(init_rng, example_batch)  # Pass the correct arguments
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 166, in init_fn
    params, state = f.init(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 422, in init_fn
    f(*args, **kwargs)
TypeError: train_model.<locals>.forward_fn() missing 1 required positional argument: 'rng'
2024-06-22 09:43:46.473752: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 09:43:46.480291: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 09:43:46.577259: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 09:43:47.993724: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-22 09:43:50,963 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 09:43:50,963 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 09:43:50,964 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 154, in <module>
    train_model(data_file)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 129, in train_model
    params = transformed_forward.init(init_rng, example_batch)  # Pass the correct arguments
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 166, in init_fn
    params, state = f.init(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 422, in init_fn
    f(*args, **kwargs)
TypeError: train_model.<locals>.forward_fn() missing 1 required positional argument: 'rng'
2024-06-22 11:29:06.381327: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 11:29:06.389287: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 11:29:06.484459: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 11:29:07.882826: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-22 11:29:10,586 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 11:29:10,586 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 11:29:10,588 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 155, in <module>
    train_model(data_file)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 128, in train_model
    params = transformed_forward.init(init_rng, example_batch)  # Pass the correct arguments
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 166, in init_fn
    params, state = f.init(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 422, in init_fn
    f(*args, **kwargs)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 103, in forward_fn
    logits = model(batch)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 464, in wrapped
    out = f(*args, **kwargs)
  File "/usr/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 305, in run_interceptors
    return bound_method(*args, **kwargs)
TypeError: VishwamAIModel.__call__() missing 1 required positional argument: 'rng'
2024-06-22 13:17:56.118802: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 13:17:56.125336: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 13:17:56.227399: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 13:17:57.631975: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py:735: UserWarning: Could not extract a code object for the object <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function object at 0x7ff27a23c0a0>
  warnings.warn("Could not extract a code object for the object %r"
WARNING:tensorflow:AutoGraph could not transform <function sig_replace_leading_parameters at 0x7ff27aa6bb50> and will run it as-is.
Cause: for/else statement not yet supported
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
2024-06-22 13:18:13,895 - WARNING - AutoGraph could not transform <function sig_replace_leading_parameters at 0x7ff27aa6bb50> and will run it as-is.
Cause: for/else statement not yet supported
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
2024-06-22 13:19:07,714 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 13:19:07,715 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 13:19:07,728 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 138, in <module>
    train_model(data_file)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 1188, in wrapper
    val = prof(func)(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 761, in f
    return func(*args, **kwds)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_file3jklou4h.py", line 39, in tf__train_model
    params = {'transformer_params': ag__.converted_call(ag__.ld(transformed_forward).init, (ag__.ld(rng), ag__.ld(example_batch)), None, fscope), 'expert_params': [ag__.converted_call(ag__.ld(transformed_forward).init, (ag__.ld(rng), ag__.ld(example_batch)), None, fscope) for _ in ag__.converted_call(ag__.ld(range), (1,), None, fscope)]}
  File "/tmp/__autograph_generated_fileviu5vxw3.py", line 36, in init_fn
    (params, state) = ag__.converted_call(ag__.ld(f).init, tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope_1)
  File "/tmp/__autograph_generated_fileon_6fru2.py", line 62, in init_fn
    ag__.converted_call(ag__.ld(f), tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope_1)
TypeError: in user code:

    File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 111, in train_model  *
        params = {
    File "/tmp/__autograph_generated_fileviu5vxw3.py", line 36, in init_fn  **
        (params, state) = ag__.converted_call(ag__.ld(f).init, tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope_1)
    File "/tmp/__autograph_generated_fileon_6fru2.py", line 62, in init_fn  **
        ag__.converted_call(ag__.ld(f), tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope_1)

    TypeError: outer_factory.<locals>.inner_factory.<locals>.tf__train_model.<locals>.create_model() missing 3 required positional arguments: 'rng', 'transformer_params', and 'expert_params'

2024-06-22 13:29:25.021961: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 13:29:25.028512: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 13:29:25.124086: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 13:29:26.788526: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py:735: UserWarning: Could not extract a code object for the object <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function object at 0x7fca9b36c130>
  warnings.warn("Could not extract a code object for the object %r"
WARNING:tensorflow:AutoGraph could not transform <function sig_replace_leading_parameters at 0x7fca9b99bb50> and will run it as-is.
Cause: for/else statement not yet supported
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
2024-06-22 13:29:43,911 - WARNING - AutoGraph could not transform <function sig_replace_leading_parameters at 0x7fca9b99bb50> and will run it as-is.
Cause: for/else statement not yet supported
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
2024-06-22 13:30:36,029 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 13:30:36,030 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 13:30:36,033 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 140, in <module>
    train_model(data_file)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 1188, in wrapper
    val = prof(func)(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 761, in f
    return func(*args, **kwds)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_filei3rq_6mv.py", line 39, in tf__train_model
    transformer_params = ag__.converted_call(ag__.ld(transformed_forward).init, (ag__.ld(rng), ag__.ld(example_batch)), None, fscope)
  File "/tmp/__autograph_generated_files6i5jfgm.py", line 36, in init_fn
    (params, state) = ag__.converted_call(ag__.ld(f).init, tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope_1)
  File "/tmp/__autograph_generated_filegaof4ie1.py", line 62, in init_fn
    ag__.converted_call(ag__.ld(f), tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope_1)
TypeError: in user code:

    File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 111, in train_model  *
        transformer_params = transformed_forward.init(rng, example_batch)
    File "/tmp/__autograph_generated_files6i5jfgm.py", line 36, in init_fn  **
        (params, state) = ag__.converted_call(ag__.ld(f).init, tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope_1)
    File "/tmp/__autograph_generated_filegaof4ie1.py", line 62, in init_fn  **
        ag__.converted_call(ag__.ld(f), tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope_1)

    TypeError: outer_factory.<locals>.inner_factory.<locals>.tf__train_model.<locals>.create_model() missing 3 required positional arguments: 'rng', 'transformer_params', and 'expert_params'

2024-06-22 16:13:12.963799: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 16:13:12.972040: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 16:13:13.078100: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 16:13:14.628045: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py:735: UserWarning: Could not extract a code object for the object <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function object at 0x7f71e1277f40>
  warnings.warn("Could not extract a code object for the object %r"
WARNING:tensorflow:AutoGraph could not transform <function sig_replace_leading_parameters at 0x7f71e18d7be0> and will run it as-is.
Cause: for/else statement not yet supported
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
2024-06-22 16:13:30,852 - WARNING - AutoGraph could not transform <function sig_replace_leading_parameters at 0x7f71e18d7be0> and will run it as-is.
Cause: for/else statement not yet supported
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
2024-06-22 16:14:22,010 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 16:14:22,011 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 16:14:22,014 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 143, in <module>
    train_model(data_file)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 1188, in wrapper
    val = prof(func)(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 761, in f
    return func(*args, **kwds)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_fileozyfmin3.py", line 39, in tf__train_model
    transformer_params = ag__.converted_call(ag__.ld(transformed_forward).init, (ag__.ld(rng), ag__.ld(example_batch)), None, fscope)
  File "/tmp/__autograph_generated_file0u3a9re5.py", line 36, in init_fn
    (params, state) = ag__.converted_call(ag__.ld(f).init, tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope_1)
  File "/tmp/__autograph_generated_file47abcm88.py", line 62, in init_fn
    ag__.converted_call(ag__.ld(f), tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope_1)
  File "/tmp/__autograph_generated_fileozyfmin3.py", line 24, in create_model
    retval__1 = ag__.converted_call(ag__.ld(model), (ag__.ld(batch),), None, fscope_1)
  File "/tmp/__autograph_generated_fileels468kw.py", line 69, in tf__wrapped
    out = ag__.converted_call(ag__.ld(f), tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope)
  File "/tmp/__autograph_generated_filevab73wu9.py", line 20, in inner
    retval__1 = ag__.converted_call(ag__.ld(func), tuple(ag__.ld(args)), dict(**ag__.ld(kwds)), fscope_1)
  File "/tmp/__autograph_generated_fileq53wom6a.py", line 76, in tf__run_interceptors
    ag__.if_stmt(ag__.not_(ag__.ld(interceptor_stack)), if_body_1, else_body_1, get_state_1, set_state_1, ('ctx', 'do_return', 'interceptor_stack_copy', 'next_fun', 'retval_'), 5)
  File "/tmp/__autograph_generated_fileq53wom6a.py", line 23, in if_body_1
    retval_ = ag__.converted_call(ag__.ld(bound_method), tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope)
  File "/tmp/__autograph_generated_filelhqaxc1q.py", line 98, in tf____call__
    embedded_inputs = ag__.converted_call(ag__.ld(self).transformer.apply, (ag__.converted_call(ag__.ld(self).transformer.init, (ag__.converted_call(ag__.ld(jax).random.PRNGKey, (42,), None, fscope), ag__.ld(inputs)), None, fscope), ag__.ld(inputs)), None, fscope)
  File "/tmp/__autograph_generated_file0u3a9re5.py", line 36, in init_fn
    (params, state) = ag__.converted_call(ag__.ld(f).init, tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope_1)
  File "/tmp/__autograph_generated_file47abcm88.py", line 62, in init_fn
    ag__.converted_call(ag__.ld(f), tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope_1)
  File "/tmp/__autograph_generated_file3j_fbdjk.py", line 11, in <lambda>
    ag__.ld(self).transformer = ag__.converted_call(ag__.ld(hk).transform, (ag__.autograph_artifact(lambda x: ag__.converted_call(ag__.converted_call(ag__.ld(hk).Sequential, ([ag__.converted_call(ag__.ld(hk).Embed, (), dict(vocab_size=20000, embed_dim=128, w_init=ag__.converted_call(ag__.ld(hk).initializers.VarianceScaling, (1.0, 'fan_avg'), None, fscope)), fscope), ag__.autograph_artifact(lambda x: ag__.converted_call(ag__.ld(self).attention, (ag__.ld(x), ag__.ld(x), ag__.ld(x)), None, fscope)), ag__.converted_call(ag__.ld(hk).Linear, (512,), dict(w_init=ag__.converted_call(ag__.ld(hk).initializers.VarianceScaling, (1.0, 'fan_avg'), None, fscope)), fscope), ag__.converted_call(ag__.ld(hk).Linear, (256,), dict(w_init=ag__.converted_call(ag__.ld(hk).initializers.VarianceScaling, (1.0, 'fan_avg'), None, fscope)), fscope)],), None, fscope), (ag__.ld(x),), None, fscope)),), dict(apply_rng=True), fscope)
  File "/tmp/__autograph_generated_fileels468kw.py", line 69, in tf__wrapped
    out = ag__.converted_call(ag__.ld(f), tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope)
  File "/tmp/__autograph_generated_filevab73wu9.py", line 20, in inner
    retval__1 = ag__.converted_call(ag__.ld(func), tuple(ag__.ld(args)), dict(**ag__.ld(kwds)), fscope_1)
  File "/tmp/__autograph_generated_fileq53wom6a.py", line 76, in tf__run_interceptors
    ag__.if_stmt(ag__.not_(ag__.ld(interceptor_stack)), if_body_1, else_body_1, get_state_1, set_state_1, ('ctx', 'do_return', 'interceptor_stack_copy', 'next_fun', 'retval_'), 5)
  File "/tmp/__autograph_generated_fileq53wom6a.py", line 23, in if_body_1
    retval_ = ag__.converted_call(ag__.ld(bound_method), tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope)
  File "/tmp/__autograph_generated_filerhb216uu.py", line 41, in tf____call__
    ag__.for_stmt(ag__.converted_call(ag__.ld(enumerate), (ag__.ld(self).layers,), None, fscope), None, loop_body, get_state_1, set_state_1, ('out',), {'iterate_names': '(i, layer)'})
  File "/tmp/__autograph_generated_filerhb216uu.py", line 38, in loop_body
    ag__.if_stmt(ag__.ld(i) == 0, if_body, else_body, get_state, set_state, ('out',), 1)
  File "/tmp/__autograph_generated_filerhb216uu.py", line 33, in if_body
    out = ag__.converted_call(ag__.ld(layer), (ag__.ld(out),) + tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope)
  File "/tmp/__autograph_generated_fileels468kw.py", line 69, in tf__wrapped
    out = ag__.converted_call(ag__.ld(f), tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope)
  File "/tmp/__autograph_generated_filevab73wu9.py", line 20, in inner
    retval__1 = ag__.converted_call(ag__.ld(func), tuple(ag__.ld(args)), dict(**ag__.ld(kwds)), fscope_1)
  File "/tmp/__autograph_generated_fileq53wom6a.py", line 76, in tf__run_interceptors
    ag__.if_stmt(ag__.not_(ag__.ld(interceptor_stack)), if_body_1, else_body_1, get_state_1, set_state_1, ('ctx', 'do_return', 'interceptor_stack_copy', 'next_fun', 'retval_'), 5)
  File "/tmp/__autograph_generated_fileq53wom6a.py", line 23, in if_body_1
    retval_ = ag__.converted_call(ag__.ld(bound_method), tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope)
  File "/tmp/__autograph_generated_filei5w54m40.py", line 27, in tf____call__
    ids = ag__.converted_call(ag__.ld(jnp).asarray, (ag__.ld(ids),), None, fscope)
  File "/tmp/__autograph_generated_filedogkyq4d.py", line 43, in tf__asarray
    retval_ = ag__.converted_call(ag__.ld(array), (ag__.ld(a),), dict(dtype=ag__.ld(dtype), copy=ag__.converted_call(ag__.ld(bool), (ag__.ld(copy),), None, fscope), order=ag__.ld(order)), fscope)
  File "/tmp/__autograph_generated_filen59xp3ul.py", line 315, in tf__array
    ag__.if_stmt(ag__.and_(lambda : ag__.not_(ag__.ld(copy)), lambda : ag__.and_(lambda : ag__.converted_call(ag__.ld(isinstance), (ag__.ld(object), ag__.ld(np).ndarray), None, fscope), lambda : ag__.and_(lambda : ag__.or_(lambda : ag__.ld(dtype) is None, lambda : ag__.ld(dtype) == ag__.ld(object).dtype), lambda : ag__.ld(ndmin) <= ag__.ld(object).ndim))), if_body_16, else_body_16, get_state_16, set_state_16, ('do_return', 'retval_', 'dtype', 'object'), 2)
  File "/tmp/__autograph_generated_filen59xp3ul.py", line 189, in else_body_16
    ag__.if_stmt(ag__.ld(dtype) is None, if_body_8, else_body_8, get_state_8, set_state_8, ('dtype', 'leaves'), 2)
  File "/tmp/__autograph_generated_filen59xp3ul.py", line 183, in if_body_8
    leaves = [ag__.converted_call(ag__.ld(_convert_to_array_if_dtype_fails), (ag__.ld(leaf),), None, fscope) for leaf in ag__.ld(leaves)]
  File "/tmp/__autograph_generated_filen59xp3ul.py", line 183, in <listcomp>
    leaves = [ag__.converted_call(ag__.ld(_convert_to_array_if_dtype_fails), (ag__.ld(leaf),), None, fscope) for leaf in ag__.ld(leaves)]
  File "/tmp/__autograph_generated_file52pv7mpc.py", line 16, in tf___convert_to_array_if_dtype_fails
    retval_ = ag__.converted_call(ag__.ld(np).asarray, (ag__.ld(x),), None, fscope)
NotImplementedError: in user code:

    File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 98, in create_model  *
        return model(batch)
    File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 75, in wrapped  *
        out = f(*args, **kwargs)
    File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 305, in run_interceptors  *
        return bound_method(*args, **kwargs)
    File "/home/ubuntu/chat-agent/VishwamAI/scripts/model_architecture.py", line 71, in __call__  *
        embedded_inputs = self.transformer.apply(self.transformer.init(jax.random.PRNGKey(42), inputs), inputs)
    File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 75, in wrapped  *
        out = f(*args, **kwargs)
    File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 305, in run_interceptors  *
        return bound_method(*args, **kwargs)
    File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/basic.py", line 126, in __call__  *
        out = layer(out, *args, **kwargs)
    File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 75, in wrapped  *
        out = f(*args, **kwargs)
    File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 305, in run_interceptors  *
        return bound_method(*args, **kwargs)
    File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/embed.py", line 166, in __call__  *
        ids = jnp.asarray(ids)
    File "/home/ubuntu/.local/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py", line 3289, in asarray  *
        return array(a, dtype=dtype, copy=bool(copy), order=order)
    File "/home/ubuntu/.local/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py", line 3185, in array  *
        leaves = [_convert_to_array_if_dtype_fails(leaf) for leaf in leaves]
    File "/home/ubuntu/.local/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py", line 3225, in _convert_to_array_if_dtype_fails  *
        return np.asarray(x)

    NotImplementedError: Cannot convert a symbolic tf.Tensor (EnsureShape:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported.

2024-06-22 16:24:46.422416: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 16:24:46.446357: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 16:24:46.739517: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 16:24:50.445785: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py:735: UserWarning: Could not extract a code object for the object <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function object at 0x7fcf8d6cc0a0>
  warnings.warn("Could not extract a code object for the object %r"
WARNING:tensorflow:AutoGraph could not transform <function sig_replace_leading_parameters at 0x7fcf8def3be0> and will run it as-is.
Cause: for/else statement not yet supported
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
2024-06-22 16:25:10,892 - WARNING - AutoGraph could not transform <function sig_replace_leading_parameters at 0x7fcf8def3be0> and will run it as-is.
Cause: for/else statement not yet supported
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
2024-06-22 16:26:25,468 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 16:26:25,469 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 16:26:25,473 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
2024-06-22 16:27:12.929487: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 16:27:12.948864: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 16:27:13.259410: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 16:27:17.929493: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py:735: UserWarning: Could not extract a code object for the object <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function object at 0x7fdedfc20250>
  warnings.warn("Could not extract a code object for the object %r"
WARNING:tensorflow:AutoGraph could not transform <function sig_replace_leading_parameters at 0x7fdee446bbe0> and will run it as-is.
Cause: for/else statement not yet supported
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
2024-06-22 16:27:53,388 - WARNING - AutoGraph could not transform <function sig_replace_leading_parameters at 0x7fdee446bbe0> and will run it as-is.
Cause: for/else statement not yet supported
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 143, in <module>
    train_model(data_file)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 1188, in wrapper
    val = prof(func)(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 761, in f
    return func(*args, **kwds)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_file1okm6pl3.py", line 39, in tf__train_model
    transformer_params = ag__.converted_call(ag__.ld(transformed_forward).init, (ag__.ld(rng), ag__.ld(example_batch), ag__.ld(rng)), None, fscope)
  File "/tmp/__autograph_generated_fileidsgvcqk.py", line 36, in init_fn
    (params, state) = ag__.converted_call(ag__.ld(f).init, tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope_1)
  File "/tmp/__autograph_generated_filea622mbuv.py", line 62, in init_fn
    ag__.converted_call(ag__.ld(f), tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope_1)
  File "/tmp/__autograph_generated_file1okm6pl3.py", line 24, in create_model
    retval__1 = ag__.converted_call(ag__.ld(model), (ag__.ld(batch), ag__.ld(rng)), None, fscope_1)
  File "/tmp/__autograph_generated_filecqf4bw16.py", line 69, in tf__wrapped
    out = ag__.converted_call(ag__.ld(f), tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope)
  File "/tmp/__autograph_generated_file4757kkzj.py", line 20, in inner
    retval__1 = ag__.converted_call(ag__.ld(func), tuple(ag__.ld(args)), dict(**ag__.ld(kwds)), fscope_1)
  File "/tmp/__autograph_generated_filek0o48ps5.py", line 76, in tf__run_interceptors
    ag__.if_stmt(ag__.not_(ag__.ld(interceptor_stack)), if_body_1, else_body_1, get_state_1, set_state_1, ('ctx', 'do_return', 'interceptor_stack_copy', 'next_fun', 'retval_'), 5)
  File "/tmp/__autograph_generated_filek0o48ps5.py", line 23, in if_body_1
    retval_ = ag__.converted_call(ag__.ld(bound_method), tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope)
TypeError: in user code:

    File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 98, in create_model  *
        return model(batch, rng)
    File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 75, in wrapped  *
        out = f(*args, **kwargs)
    File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 305, in run_interceptors  *
        return bound_method(*args, **kwargs)

    TypeError: outer_factory.<locals>.inner_factory.<locals>.tf____call__() takes 2 positional arguments but 3 were given

2024-06-22 16:29:22,851 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 16:29:22,852 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 16:29:22,855 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 143, in <module>
    train_model(data_file)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 1188, in wrapper
    val = prof(func)(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 761, in f
    return func(*args, **kwds)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_fileb_mt2zpn.py", line 39, in tf__train_model
    transformer_params = ag__.converted_call(ag__.ld(transformed_forward).init, (ag__.ld(rng), ag__.ld(example_batch)), None, fscope)
  File "/tmp/__autograph_generated_file3pp6o1m6.py", line 36, in init_fn
    (params, state) = ag__.converted_call(ag__.ld(f).init, tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope_1)
  File "/tmp/__autograph_generated_fileif8bz8em.py", line 62, in init_fn
    ag__.converted_call(ag__.ld(f), tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope_1)
TypeError: in user code:

    File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 114, in train_model  *
        transformer_params = transformed_forward.init(rng, example_batch)
    File "/tmp/__autograph_generated_file3pp6o1m6.py", line 36, in init_fn  **
        (params, state) = ag__.converted_call(ag__.ld(f).init, tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope_1)
    File "/tmp/__autograph_generated_fileif8bz8em.py", line 62, in init_fn  **
        ag__.converted_call(ag__.ld(f), tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope_1)

    TypeError: outer_factory.<locals>.inner_factory.<locals>.tf__train_model.<locals>.create_model() missing 1 required positional argument: 'rng'

2024-06-22 20:45:17.638130: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 20:45:17.657334: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 20:45:17.759995: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 20:45:19.170872: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-22 20:45:22,738 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 20:45:22,739 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 20:45:22,742 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
Data type of inputs after conversion: <dtype: 'int32'>
Data type of inputs before embedding layer: <dtype: 'int32'>
Data type of inputs after conversion to int32: <dtype: 'int32'>
Data type of inputs before transformer apply: <dtype: 'int32'>
Data type of embedded inputs after transformer apply: float32
Shape of expert_inputs: (8, 32, 256)
Data type of expert output after conversion to float32: <dtype: 'float32'>
Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 142, in <module>
    train_model(data_file)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 1188, in wrapper
    val = prof(func)(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 761, in f
    return func(*args, **kwds)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 113, in train_model
    transformer_params = transformed_forward.init(rng, example_batch)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 166, in init_fn
    params, state = f.init(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 422, in init_fn
    f(*args, **kwargs)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 97, in create_model
    return model(batch)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 464, in wrapped
    out = f(*args, **kwargs)
  File "/usr/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 305, in run_interceptors
    return bound_method(*args, **kwargs)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/model_architecture.py", line 94, in __call__
    output = self.dense(tf.cast(attention_output, np.float32))  # Ensure the data type is float32
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 464, in wrapped
    out = f(*args, **kwargs)
  File "/usr/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 305, in run_interceptors
    return bound_method(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/basic.py", line 179, in __call__
    w = hk.get_parameter("w", [input_size, output_size], dtype, init=w_init)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/base.py", line 658, in get_parameter
    param = init(shape, dtype)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/initializers.py", line 226, in __call__
    distribution_stddev = np.asarray(.87962566103423978, dtype=dtype)
TypeError: Cannot interpret 'tf.float32' as a data type
2024-06-22 20:51:18.746518: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 20:51:18.754772: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 20:51:18.962089: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 20:51:22.137266: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-22 20:51:30,946 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 20:51:30,947 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 20:51:30,952 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 142, in <module>
    train_model(data_file)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 1188, in wrapper
    val = prof(func)(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 761, in f
    return func(*args, **kwds)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 113, in train_model
    transformer_params = transformed_forward.init(rng, example_batch)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 166, in init_fn
    params, state = f.init(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 422, in init_fn
    f(*args, **kwargs)
TypeError: train_model.<locals>.create_model() missing 1 required positional argument: 'rng'
2024-06-22 20:55:25.418169: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 20:55:25.425201: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 20:55:25.518514: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 20:55:26.850586: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-22 20:55:30,269 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 20:55:30,270 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 20:55:30,273 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 143, in <module>
    train_model(data_file)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 1188, in wrapper
    val = prof(func)(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 761, in f
    return func(*args, **kwds)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 114, in train_model
    transformer_params = transformed_forward.init(rng, example_batch)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 166, in init_fn
    params, state = f.init(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 422, in init_fn
    f(*args, **kwargs)
TypeError: train_model.<locals>.create_model() missing 1 required positional argument: 'rng'
2024-06-22 21:36:41.946808: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 21:36:41.955514: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 21:36:42.093260: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 21:36:45.355224: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-22 21:36:53,304 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 21:36:53,310 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 21:36:53,328 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
Data type of inputs after conversion: <dtype: 'int32'>
Data type of inputs before embedding layer: <dtype: 'int32'>
Data type of inputs after conversion to int32: <dtype: 'int32'>
Data type of inputs before transformer apply: <dtype: 'int32'>
Data type of embedded inputs after transformer apply: float32
Shape of expert_inputs: (8, 32, 256)
Data type of expert output after conversion to float32: <dtype: 'float32'>
Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 147, in <module>
    train_model(data_file)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 1188, in wrapper
    val = prof(func)(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 761, in f
    return func(*args, **kwds)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 115, in train_model
    transformer_params = transformed_forward.init(transformer_rng, example_batch)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 166, in init_fn
    params, state = f.init(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 422, in init_fn
    f(*args, **kwargs)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 97, in create_model
    return model(batch)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 464, in wrapped
    out = f(*args, **kwargs)
  File "/usr/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 305, in run_interceptors
    return bound_method(*args, **kwargs)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/model_architecture.py", line 94, in __call__
    output = self.dense(tf.cast(attention_output, tf.float32))  # Ensure the data type is float32
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 464, in wrapped
    out = f(*args, **kwargs)
  File "/usr/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 305, in run_interceptors
    return bound_method(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/basic.py", line 179, in __call__
    w = hk.get_parameter("w", [input_size, output_size], dtype, init=w_init)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/base.py", line 658, in get_parameter
    param = init(shape, dtype)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/initializers.py", line 226, in __call__
    distribution_stddev = np.asarray(.87962566103423978, dtype=dtype)
TypeError: Cannot interpret 'tf.float32' as a data type
2024-06-23 05:09:23.004909: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-23 05:09:23.013402: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-23 05:09:23.109705: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-23 05:09:24.531735: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-23 05:09:27,696 - INFO - Unable to initialize backend 'cuda': 
2024-06-23 05:09:27,697 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-23 05:09:27,700 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
Data type of inputs after conversion: <dtype: 'int32'>
Data type of inputs before embedding layer: <dtype: 'int32'>
Data type of inputs after conversion to int32: <dtype: 'int32'>
Data type of inputs before transformer apply: <dtype: 'int32'>
Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 150, in <module>
    train_model(data_file)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 1188, in wrapper
    val = prof(func)(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 761, in f
    return func(*args, **kwds)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 118, in train_model
    transformer_params = transformed_forward.init(transformer_rng, example_batch)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 166, in init_fn
    params, state = f.init(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 422, in init_fn
    f(*args, **kwargs)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 101, in create_model
    return model(batch)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 464, in wrapped
    out = f(*args, **kwargs)
  File "/usr/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 305, in run_interceptors
    return bound_method(*args, **kwargs)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/model_architecture.py", line 74, in __call__
    embedded_inputs = self.dropout(embedded_inputs, rate=0.1)
TypeError: dropout() missing 1 required positional argument: 'x'
