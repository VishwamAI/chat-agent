nohup: ignoring input
2024-06-22 23:11:05.472044: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 23:11:05.483533: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 23:11:05.589953: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 23:11:07.156810: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-22 23:11:10,687 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 23:11:10,687 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 23:11:10,691 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
Data type of inputs after conversion: <dtype: 'int32'>
Data type of inputs before embedding layer: <dtype: 'int32'>
Data type of inputs after conversion to int32: <dtype: 'int32'>
Data type of inputs before transformer apply: <dtype: 'int32'>
Data type of embedded inputs after transformer apply: float32
Shape of expert_inputs: (8, 32, 256)
Data type of expert output after conversion to float32: <dtype: 'float32'>
Data type of inputs after conversion: <dtype: 'int32'>
Data type of inputs before embedding layer: <dtype: 'int32'>
Data type of inputs after conversion to int32: <dtype: 'int32'>
Data type of inputs before transformer apply: <dtype: 'int32'>
Data type of embedded inputs after transformer apply: float32
Shape of expert_inputs: (8, 32, 256)
Data type of expert output after conversion to float32: <dtype: 'float32'>
2024-06-22 23:11:59,049 - INFO - Data type of batch before model apply: <dtype: 'int32'>
jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 148, in <module>
    train_model(data_file)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 1188, in wrapper
    val = prof(func)(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 761, in f
    return func(*args, **kwds)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 134, in train_model
    loss, params, opt_state = train_step(params, transformed_forward, optimizer, batch, labels, step_rng)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 82, in train_step
    loss, grads = jax.value_and_grad(jax.checkpoint(loss_fn))(params)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 74, in loss_fn
    logits = transformed_forward.apply(params, rng, batch_jax)  # logits shape: [batch_size, num_classes]
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 183, in apply_fn
    out, state = f.apply(params, None, *args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 456, in apply_fn
    out = f(*args, **kwargs)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 99, in create_model
    return model(batch)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 464, in wrapped
    out = f(*args, **kwargs)
  File "/usr/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 305, in run_interceptors
    return bound_method(*args, **kwargs)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/model_architecture.py", line 61, in __call__
    raise ValueError("Input must be of type `str`, `List[str]`, `List[List[int]]`, or a TensorFlow tensor")
ValueError: Input must be of type `str`, `List[str]`, `List[List[int]]`, or a TensorFlow tensor
