nohup: ignoring input
2024-06-22 01:42:36.451583: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 01:42:36.458061: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-22 01:42:36.544375: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-22 01:42:37.803872: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-22 01:42:40,665 - INFO - Unable to initialize backend 'cuda': 
2024-06-22 01:42:40,666 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2024-06-22 01:42:40,669 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
Data type of inputs after conversion: <dtype: 'int32'>
Data type of inputs before embedding layer: <dtype: 'int32'>
Data type of inputs after conversion to int32: <dtype: 'int32'>
Data type of inputs before transformer apply: <dtype: 'int32'>
Traceback (most recent call last):
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 151, in <module>
    train_model(data_file)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 1188, in wrapper
    val = prof(func)(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/memory_profiler.py", line 761, in f
    return func(*args, **kwds)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 126, in train_model
    params = transformed_forward.init(init_rng, example_batch)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 166, in init_fn
    params, state = f.init(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 422, in init_fn
    f(*args, **kwargs)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/train_vishwamai_model.py", line 101, in forward_fn
    logits = model(batch)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 464, in wrapped
    out = f(*args, **kwargs)
  File "/usr/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/module.py", line 305, in run_interceptors
    return bound_method(*args, **kwargs)
  File "/home/ubuntu/chat-agent/VishwamAI/scripts/model_architecture.py", line 72, in __call__
    embedded_inputs = self.transformer.apply(inputs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/haiku/_src/transform.py", line 183, in apply_fn
    out, state = f.apply(params, None, *args, **kwargs)
TypeError: transform_with_state.<locals>.apply_fn() missing 1 required positional argument: 'rng'
